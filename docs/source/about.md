```eval_rst
.. image:: bark_logo.jpg
   :align: center
```

&nbsp;


About Bark
==========================
The name BArk is derived from **B**ehavior Benchm**Ark**. BArk focuses on the development and evaluation of behavior generation components for autonomous driving.

## Need
Autonomous agents, such as traffic participants, need to make decisions in uncertain environments having many agents, which might be cooperative or possibly adversarial. Research in decision making brought up many approaches from the fields of machine learning, game, and control theory. However, transferring approaches to real-world applications, such as self-driving cars introduces a number of challenges, that prevent such systems to safely enter the market. One of the remaining challenges is a quantification of the expected performance of behavior generation approaches under true environmental conditions, e.g. unknown true behavior of other participants or uncertainty regarding the observations of the environment. This challenge is currently approached by driving endless amounts of kilometers in simulation-based and in recorded scenarios. However, such an approach impedes getting insights into the causes of performance differences of the evaluated approaches. Implemented improvements of an approach require frequent re-evaluation over the whole set of scenarios. To make behavior generation approaches ready for the real-world, an analysis framework should be established which can accurately model the divergence between real behavior of other participants and the behaviors generated by models (algorithms). Such a framework would allow for a more thorough investigation of the expected performance of behavior generation approaches under true environmental conditions. To make the claims of simulation-based performance results transferable to reality, benchmark scenario specifications must be selected according to certain coverage criteria and agreed on by the whole community of researchers and industry. BArk tries to tackle and solve the above mentioned challenges and problems.


## BArk Concept
BArk is a multi-agent simulation environment tailored towards the use case of autonomous systems, with a special focus on autonomous driving. Each agent is controlled by a behavior specification in form of a behavioral model. Behavioral models can be easily exchanged and used both for simulation of other participants and/or as behavior prediction on the behavior generation side. For this, Bark defines abstract interfaces for the development of own behavioral models but also delivers several state-of-the-art behavioral models based on machine-learning and classical approaches. By additionally having a set of metrics and functions that evaluate individual components, BArk acts as a comprehensive framework for the development and verification of behavior generation approaches.

## BArk Architecture
BArks modular architecture is as follows: 

```eval_rst
.. image:: overview.png
   :width: 100%
   :align: center
```


## Existing Simulation Environments
There are already simulation solutions around, which also provide validation and benchmarking tools. Without a claim of completeness, we shortly compare them to BArk's goals. 
* **Vehicle-centered component-based simulations** like veDyna (Tesis), Carmaker (IPG), ASM (dSpace), rFpro: Build around a complex an accurate model of the ego vehicle's dynamics, driving performance, or consumption can accurately be simulated. Primarily use case: (ADAS) control units HiL tests and homologation, also environment and traffic can be simulated. The focus is not on diverse behavior models of the traffic participants as the ego vehicle is considered as a test unit.

* **Multibody physics-based simulations** like Gazebo, SimScape/SimMechanics (Mathworks), Modelica libraries (VDL, Modelon): Correct simulation of the underlying physics is of importance and e.g. accurate sensor models can be achieved using ray tracing. The focus is not simulating the whole traffic scene with agent behaviors due to over-complexity.

* **Game engine simulators** like Carla (Intel), or AirSim (Microsoft): Based on a modern game engine, vision-based sensors and visualizations can be evaluated. Here models for the environment and the ego vehicle are present but a variety of behavior models for traffic is missing.

* **Traffic simulation** like Vissim (PTV), or Sumo (DLR): Microscopic traffic simulation allows individual simulation of each agent but without benchmarking and autonomous driving capacities. The ”BEHAVE” project aims to add more sophisticated models for agents (human-driven and autonomously) to CityMoS.

* **Vehicle environment simulations** like Vires Virtual Test Drive (MSC) focus on the visualization and simulation of the environment and sensor setup and the testing process and not on the intelligence of the traffic agents.

* **Atari game simulations** are primarily focused on fundamental research on decision making. 

* **Robotics benchmarking libraries** like Drake (MIT) or OMPL do not cover agent models for behavior benchmarks.


